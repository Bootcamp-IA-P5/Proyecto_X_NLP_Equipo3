{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f30a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cpu\n",
      "BASE_DIR : C:\\Users\\Administrator\\Desktop\\NLP\\Proyecto_X_NLP_Equipo3\n",
      "DATA_DIR : C:\\Users\\Administrator\\Desktop\\NLP\\Proyecto_X_NLP_Equipo3\\data\\processed\n",
      "MODELS_DIR: C:\\Users\\Administrator\\Desktop\\NLP\\Proyecto_X_NLP_Equipo3\\models\n",
      "MLRUNS_DIR: C:\\Users\\Administrator\\Desktop\\NLP\\Proyecto_X_NLP_Equipo3\\mlruns\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1. IMPORTS Y CONFIGURACIÓN\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Para reproducibilidad\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", DEVICE)\n",
    "\n",
    "# Rutas (ajusta si tu estructura es distinta)\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "DATA_DIR = BASE_DIR / \"data/processed\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "MLRUNS_DIR = BASE_DIR / \"mlruns\"\n",
    "\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "MLRUNS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"BASE_DIR :\", BASE_DIR)\n",
    "print(\"DATA_DIR :\", DATA_DIR)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)\n",
    "print(\"MLRUNS_DIR:\", MLRUNS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc74a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del DataFrame: (997, 39)\n",
      "Columnas: ['CommentId', 'VideoId', 'Text', 'IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', 'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', 'IsHomophobic', 'IsReligiousHate', 'IsRadicalism', 'IsHate', 'num_labels', 'char_count', 'word_count', 'sentence_count', 'avg_word_length', 'uppercase_count', 'uppercase_ratio', 'exclamation_count', 'question_count', 'dots_count', 'emoji_count', 'url_count', 'mention_count', 'hashtag_count', 'number_count', 'Text_Clean_Basic', 'char_count_clean', 'word_count_clean', 'Text_Clean_Advanced', 'Text_No_Stopwords', 'word_count_no_stop', 'Text_Stemmed', 'Text_Lemmatized']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "      <th>IsAbusive</th>\n",
       "      <th>IsThreat</th>\n",
       "      <th>IsProvocative</th>\n",
       "      <th>IsObscene</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>IsRacist</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>number_count</th>\n",
       "      <th>Text_Clean_Basic</th>\n",
       "      <th>char_count_clean</th>\n",
       "      <th>word_count_clean</th>\n",
       "      <th>Text_Clean_Advanced</th>\n",
       "      <th>Text_No_Stopwords</th>\n",
       "      <th>word_count_no_stop</th>\n",
       "      <th>Text_Stemmed</th>\n",
       "      <th>Text_Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>1548</td>\n",
       "      <td>287</td>\n",
       "      <td>if only people would just take a step back and...</td>\n",
       "      <td>people would take step back make case them, an...</td>\n",
       "      <td>134</td>\n",
       "      <td>peopl would take step back make case them, any...</td>\n",
       "      <td>people would take step back make case them, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>136</td>\n",
       "      <td>25</td>\n",
       "      <td>law enforcement is not trained to shoot to app...</td>\n",
       "      <td>law enforcement trained shoot apprehend. train...</td>\n",
       "      <td>13</td>\n",
       "      <td>law enforc train shoot apprehend. train shoot ...</td>\n",
       "      <td>law enforcement trained shoot apprehend. train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\nDont you reckon them 'black lives matter' ba...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dont you reckon them 'black lives matter' bann...</td>\n",
       "      <td>418</td>\n",
       "      <td>77</td>\n",
       "      <td>dont you reckon them 'black lives matter' bann...</td>\n",
       "      <td>dont reckon 'black lives matter' banners held ...</td>\n",
       "      <td>40</td>\n",
       "      <td>dont reckon 'black live matter' banner held wh...</td>\n",
       "      <td>dont reckon 'black life matter' banner held wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>582</td>\n",
       "      <td>107</td>\n",
       "      <td>there are a very large number of people who do...</td>\n",
       "      <td>large number people like police officers. call...</td>\n",
       "      <td>49</td>\n",
       "      <td>larg number peopl like polic officers. call cr...</td>\n",
       "      <td>large number people like police officers. call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>242</td>\n",
       "      <td>47</td>\n",
       "      <td>the arab dude is absolutely right, he should h...</td>\n",
       "      <td>arab dude absolutely right, shot extra time. s...</td>\n",
       "      <td>23</td>\n",
       "      <td>arab dude absolut right, shot extra time. shoo...</td>\n",
       "      <td>arab dude absolutely right, shot extra time. s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  IsAbusive  \\\n",
       "0  If only people would just take a step back and...    False      False   \n",
       "1  Law enforcement is not trained to shoot to app...     True       True   \n",
       "2  \\nDont you reckon them 'black lives matter' ba...     True       True   \n",
       "3  There are a very large number of people who do...    False      False   \n",
       "4  The Arab dude is absolutely right, he should h...    False      False   \n",
       "\n",
       "   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  ...  \\\n",
       "0     False          False      False         False     False  ...   \n",
       "1     False          False      False         False     False  ...   \n",
       "2     False          False       True         False     False  ...   \n",
       "3     False          False      False         False     False  ...   \n",
       "4     False          False      False         False     False  ...   \n",
       "\n",
       "   hashtag_count  number_count  \\\n",
       "0              0             2   \n",
       "1              0             0   \n",
       "2              0             0   \n",
       "3              0             0   \n",
       "4              0             1   \n",
       "\n",
       "                                    Text_Clean_Basic  char_count_clean  \\\n",
       "0  If only people would just take a step back and...              1548   \n",
       "1  Law enforcement is not trained to shoot to app...               136   \n",
       "2  Dont you reckon them 'black lives matter' bann...               418   \n",
       "3  There are a very large number of people who do...               582   \n",
       "4  The Arab dude is absolutely right, he should h...               242   \n",
       "\n",
       "   word_count_clean                                Text_Clean_Advanced  \\\n",
       "0               287  if only people would just take a step back and...   \n",
       "1                25  law enforcement is not trained to shoot to app...   \n",
       "2                77  dont you reckon them 'black lives matter' bann...   \n",
       "3               107  there are a very large number of people who do...   \n",
       "4                47  the arab dude is absolutely right, he should h...   \n",
       "\n",
       "                                   Text_No_Stopwords  word_count_no_stop  \\\n",
       "0  people would take step back make case them, an...                 134   \n",
       "1  law enforcement trained shoot apprehend. train...                  13   \n",
       "2  dont reckon 'black lives matter' banners held ...                  40   \n",
       "3  large number people like police officers. call...                  49   \n",
       "4  arab dude absolutely right, shot extra time. s...                  23   \n",
       "\n",
       "                                        Text_Stemmed  \\\n",
       "0  peopl would take step back make case them, any...   \n",
       "1  law enforc train shoot apprehend. train shoot ...   \n",
       "2  dont reckon 'black live matter' banner held wh...   \n",
       "3  larg number peopl like polic officers. call cr...   \n",
       "4  arab dude absolut right, shot extra time. shoo...   \n",
       "\n",
       "                                     Text_Lemmatized  \n",
       "0  people would take step back make case them, an...  \n",
       "1  law enforcement trained shoot apprehend. train...  \n",
       "2  dont reckon 'black life matter' banner held wh...  \n",
       "3  large number people like police officers. call...  \n",
       "4  arab dude absolutely right, shot extra time. s...  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. CARGA DEL DATASET PROCESADO (PICKLE)\n",
    "# ==========================================\n",
    "\n",
    "pkl_path = DATA_DIR / \"youtube_all_versions.pkl\"\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Si el pickle es un DataFrame directamente:\n",
    "if isinstance(data, pd.DataFrame):\n",
    "    df = data.copy()\n",
    "else:\n",
    "    # Si el pickle es un dict con varias versiones, elegimos una clave.\n",
    "    # AJUSTA 'text_clean' A LA CLAVE REAL QUE HAYAS USADO EN EL PREPROCESAMIENTO.\n",
    "    # Por ejemplo podría ser: 'Text_clean', 'text_processed', etc.\n",
    "    print(\"Claves disponibles en el pickle:\", list(data.keys()))\n",
    "    df = data[\"text_clean\"].copy()\n",
    "\n",
    "print(\"Dimensiones del DataFrame:\", df.shape)\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Comprobamos presencia de columnas clave\n",
    "assert \"Text\" in df.columns, \"No se encontró la columna 'Text' en el DataFrame.\"\n",
    "assert \"IsHate\" in df.columns, \"No se encontró la columna 'IsHate' en el DataFrame.\"\n",
    "\n",
    "# Vista rápida\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ce74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases (IsHate):\n",
      "IsHate\n",
      "False    0.539619\n",
      "True     0.460381\n",
      "Name: ratio, dtype: float64\n",
      "Tamaños:\n",
      "  Train: 637\n",
      "  Val  : 160\n",
      "  Test : 200\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 3. SELECCIÓN DE COLUMNAS Y SPLIT TRAIN / VAL / TEST\n",
    "# =======================================================\n",
    "\n",
    "TEXT_COL = \"Text\"     # nombre exacto de la columna de texto\n",
    "TARGET_COL = \"IsHate\" # 0 = normal, 1 = odio\n",
    "\n",
    "# Subconjunto mínimo necesario\n",
    "df_model = df[[TEXT_COL, TARGET_COL]].dropna().copy()\n",
    "\n",
    "print(\"Distribución de clases (IsHate):\")\n",
    "print(df_model[TARGET_COL].value_counts(normalize=True).rename(\"ratio\"))\n",
    "\n",
    "X = df_model[TEXT_COL].values\n",
    "y = df_model[TARGET_COL].values.astype(int)\n",
    "\n",
    "# Train+Val vs Test (por ejemplo 80/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# Dentro de Train+Val, reservamos un 20% para validación (=> 64/16/20 global aprox.)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"  Train:\", len(X_train))\n",
    "print(\"  Val  :\", len(X_val))\n",
    "print(\"  Test :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3faee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuentos antes de augment: {np.int64(0): np.int64(344), np.int64(1): np.int64(293)}\n",
      "Recuentos después de augment: {np.int64(0): np.int64(344), np.int64(1): np.int64(380)}\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 4. DATA AUGMENTATION LIGERO (OPCIONAL)\n",
    "# ===================================================\n",
    "# Aquí se hace un ejemplo muy simple: duplicar aleatoriamente algunos ejemplos\n",
    "# de la clase minoritaria con pequeñas perturbaciones (ej. shuffle de palabras).\n",
    "# Puedes sustituir esto por back-translation u otra técnica más sofisticada.\n",
    "\n",
    "def simple_word_shuffle(text, max_swaps=2):\n",
    "    words = text.split()\n",
    "    if len(words) < 4:\n",
    "        return text\n",
    "    n_swaps = random.randint(1, max_swaps)\n",
    "    words = words.copy()\n",
    "    for _ in range(n_swaps):\n",
    "        i, j = random.sample(range(len(words)), 2)\n",
    "        words[i], words[j] = words[j], words[i]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def augment_minority(X, y, factor=0.3):\n",
    "    X = list(X)\n",
    "    y = list(y)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Identificar clase minoritaria\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_counts = dict(zip(unique, counts))\n",
    "    print(\"Recuentos antes de augment:\", class_counts)\n",
    "\n",
    "    minority_class = min(class_counts, key=class_counts.get)\n",
    "    maj_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "    n_min = class_counts[minority_class]\n",
    "    n_maj = class_counts[maj_class]\n",
    "\n",
    "    # Número de nuevos ejemplos (por factor sobre minoria)\n",
    "    n_new = int(n_min * factor)\n",
    "    if n_new == 0:\n",
    "        return X, y\n",
    "\n",
    "    minority_indices = np.where(y == minority_class)[0]\n",
    "    new_texts = []\n",
    "    new_labels = []\n",
    "\n",
    "    for _ in range(n_new):\n",
    "        idx = random.choice(minority_indices)\n",
    "        original_text = X[idx]\n",
    "        aug_text = simple_word_shuffle(original_text)\n",
    "        new_texts.append(aug_text)\n",
    "        new_labels.append(minority_class)\n",
    "\n",
    "    X_aug = np.concatenate([X, np.array(new_texts)])\n",
    "    y_aug = np.concatenate([y, np.array(new_labels)])\n",
    "\n",
    "    unique2, counts2 = np.unique(y_aug, return_counts=True)\n",
    "    print(\"Recuentos después de augment:\", dict(zip(unique2, counts2)))\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "# Aplica augment solo al conjunto de entrenamiento\n",
    "X_train_aug, y_train_aug = augment_minority(X_train, y_train, factor=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbee636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724, 160, 200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. TOKENIZER Y DATASETS PARA TRANSFORMERS\n",
    "# ==============================================\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"  # puedes cambiarlo\n",
    "MAX_LENGTH = 128                  # ajusta si tus textos son más largos\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class HateDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = HateDataset(X_train_aug, y_train_aug, tokenizer, MAX_LENGTH)\n",
    "val_dataset   = HateDataset(X_val,      y_val,      tokenizer, MAX_LENGTH)\n",
    "test_dataset  = HateDataset(X_test,     y_test,     tokenizer, MAX_LENGTH)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09afc29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([1.0523, 0.9526])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# 6. CÁLCULO DE CLASS WEIGHTS (OPCIONAL)\n",
    "# =======================================\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array([0, 1]),\n",
    "    y=y_train_aug\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "print(\"Class weights:\", class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a55e93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 184 Warmup steps: 11\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. MODELO MULTILINGUAL BERT + OPTIMIZADOR + SCHEDULER\n",
    "# ==========================================\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "MULTILINGUAL_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "num_labels = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MULTILINGUAL_MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"bert.encoder.layer.\") and int(name.split(\".\")[3]) < 8:\n",
    "        param.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "EPOCHS = 4\n",
    "LR = 1e-5\n",
    "WARMUP_RATIO = 0.06\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LR,\n",
    "    weight_decay=0.05\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"Total steps:\", total_steps, \"Warmup steps:\", warmup_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88080f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 8. FUNCIONES TRAIN / EVAL LOOP\n",
    "# ===================================\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=None\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Grad clipping para estabilidad\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=None\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, f1, precision, recall, all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4071d0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:C:\\Users\\Administrator\\Desktop\\NLP\\Proyecto_X_NLP_Equipo3\\mlruns\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 9. CONFIGURACIÓN DE MLFLOW\n",
    "# ==============================\n",
    "\n",
    "# Directorio donde se guardan los mlruns al mismo nivel que notebooks\n",
    "mlflow.set_tracking_uri(f\"file:{MLRUNS_DIR}\")\n",
    "mlflow.set_experiment(\"bert_hate_detection_youtube\")\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a0035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/4 =====\n",
      "Train  - Loss: 0.7006 | F1: 0.5062 | P: 0.5271 | R: 0.4868\n",
      "Val    - Loss: 0.6926 | F1: 0.4336 | P: 0.4493 | R: 0.4189\n",
      "Diff F1 (train - val): 0.0726\n",
      ">>> Nuevo mejor modelo (F1 val).\n",
      "\n",
      "===== Epoch 2/4 =====\n",
      "Train  - Loss: 0.6944 | F1: 0.6150 | P: 0.5251 | R: 0.7421\n",
      "Val    - Loss: 0.6925 | F1: 0.3103 | P: 0.4286 | R: 0.2432\n",
      "Diff F1 (train - val): 0.3047\n",
      "Sin mejora en F1 val. Patience 1/2\n",
      "\n",
      "===== Epoch 3/4 =====\n",
      "Train  - Loss: 0.6973 | F1: 0.4411 | P: 0.5177 | R: 0.3842\n",
      "Val    - Loss: 0.6905 | F1: 0.3119 | P: 0.4857 | R: 0.2297\n",
      "Diff F1 (train - val): 0.1292\n",
      "Sin mejora en F1 val. Patience 2/2\n",
      ">>> Early stopping activado.\n",
      "\n",
      "Resultados finales en VALIDACIÓN:\n",
      "Loss: 0.6905 | F1: 0.3119 | P: 0.4857 | R: 0.2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 14:54:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 train final: 0.5060 | Diff F1 final (train - val): 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 14:54:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 10. ENTRENAMIENTO CON MLFLOW + EARLY STOPPING\n",
    "#     (control overfitting <~5 puntos F1 train-val)\n",
    "# ======================================================\n",
    "\n",
    "PATIENCE = 2  # epochs sin mejora para parar\n",
    "BEST_VAL_F1 = 0.0\n",
    "PATIENCE_COUNTER = 0\n",
    "\n",
    "best_model_state = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"bert_base_youtube_hate\") as run:\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"max_length\", MAX_LENGTH)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"warmup_ratio\", WARMUP_RATIO)\n",
    "    mlflow.log_param(\"seed\", SEED)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"\\n===== Epoch {epoch}/{EPOCHS} =====\")\n",
    "\n",
    "        train_loss, train_f1, train_prec, train_rec = train_one_epoch(\n",
    "            model, train_loader, optimizer, scheduler, criterion, DEVICE\n",
    "        )\n",
    "        val_loss, val_f1, val_prec, val_rec, _, _ = eval_one_epoch(\n",
    "            model, val_loader, criterion, DEVICE\n",
    "        )\n",
    "\n",
    "        print(f\"Train  - Loss: {train_loss:.4f} | F1: {train_f1:.4f} | P: {train_prec:.4f} | R: {train_rec:.4f}\")\n",
    "        print(f\"Val    - Loss: {val_loss:.4f} | F1: {val_f1:.4f} | P: {val_prec:.4f} | R: {val_rec:.4f}\")\n",
    "\n",
    "        # Diferencia de F1 (aprox. overfitting)\n",
    "        f1_diff = train_f1 - val_f1\n",
    "        print(f\"Diff F1 (train - val): {f1_diff:.4f}\")\n",
    "\n",
    "        # Log en MLflow\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_f1\", train_f1, step=epoch)\n",
    "        mlflow.log_metric(\"train_precision\", train_prec, step=epoch)\n",
    "        mlflow.log_metric(\"train_recall\", train_rec, step=epoch)\n",
    "\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_f1\", val_f1, step=epoch)\n",
    "        mlflow.log_metric(\"val_precision\", val_prec, step=epoch)\n",
    "        mlflow.log_metric(\"val_recall\", val_rec, step=epoch)\n",
    "        mlflow.log_metric(\"f1_diff_train_val\", f1_diff, step=epoch)\n",
    "\n",
    "        # Early stopping por F1 de validación\n",
    "        if val_f1 > BEST_VAL_F1:\n",
    "            BEST_VAL_F1 = val_f1\n",
    "            PATIENCE_COUNTER = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(\">>> Nuevo mejor modelo (F1 val).\")\n",
    "        else:\n",
    "            PATIENCE_COUNTER += 1\n",
    "            print(f\"Sin mejora en F1 val. Patience {PATIENCE_COUNTER}/{PATIENCE}\")\n",
    "            if PATIENCE_COUNTER >= PATIENCE:\n",
    "                print(\">>> Early stopping activado.\")\n",
    "                break\n",
    "\n",
    "    # Restaurar mejores pesos\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Evaluación final en validación después de early stopping\n",
    "    val_loss, val_f1, val_prec, val_rec, _, _ = eval_one_epoch(\n",
    "        model, val_loader, criterion, DEVICE\n",
    "    )\n",
    "    print(\"\\nResultados finales en VALIDACIÓN:\")\n",
    "    print(f\"Loss: {val_loss:.4f} | F1: {val_f1:.4f} | P: {val_prec:.4f} | R: {val_rec:.4f}\")\n",
    "    mlflow.log_metric(\"final_val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"final_val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"final_val_precision\", val_prec)\n",
    "    mlflow.log_metric(\"final_val_recall\", val_rec)\n",
    "\n",
    "    # Puedes loguear también la diferencia de F1 final (medida de overfitting)\n",
    "    train_loss_final, train_f1_final, _, _ = train_one_epoch(\n",
    "        model, train_loader, optimizer, scheduler, criterion, DEVICE\n",
    "    )\n",
    "    f1_diff_final = train_f1_final - val_f1\n",
    "    print(f\"F1 train final: {train_f1_final:.4f} | Diff F1 final (train - val): {f1_diff_final:.4f}\")\n",
    "    mlflow.log_metric(\"final_train_f1\", train_f1_final)\n",
    "    mlflow.log_metric(\"final_f1_diff_train_val\", f1_diff_final)\n",
    "\n",
    "    # Log del modelo en MLflow\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e68d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados en TEST:\n",
      "Loss: 0.6913\n",
      "F1  : 0.4615\n",
      "P   : 0.5625\n",
      "R   : 0.3913\n",
      "\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5882    0.7407    0.6557       108\n",
      "           1     0.5625    0.3913    0.4615        92\n",
      "\n",
      "    accuracy                         0.5800       200\n",
      "   macro avg     0.5754    0.5660    0.5586       200\n",
      "weighted avg     0.5764    0.5800    0.5664       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 11. EVALUACIÓN EN CONJUNTO TEST\n",
    "# ===============================\n",
    "\n",
    "test_loss, test_f1, test_prec, test_rec, y_true_test, y_pred_test = eval_one_epoch(\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(\"Resultados en TEST:\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"F1  : {test_f1:.4f}\")\n",
    "print(f\"P   : {test_prec:.4f}\")\n",
    "print(f\"R   : {test_rec:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report (TEST):\")\n",
    "print(classification_report(y_true_test, y_pred_test, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3d0b401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando modelo en: C:\\Users\\Administrator\\Desktop\\NLP\\Proyecto_X_NLP_Equipo3\\models\\bert_youtube_hate\n",
      "Modelo y configuración guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 12. GUARDADO DEL MODELO Y TOKENIZER (../models)\n",
    "# =============================================\n",
    "\n",
    "final_model_dir = MODELS_DIR / \"bert_youtube_hate\"\n",
    "final_model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Guardando modelo en:\", final_model_dir)\n",
    "\n",
    "# Guardar modelo y tokenizer al estilo Hugging Face\n",
    "model.save_pretrained(final_model_dir)\n",
    "tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "# Guardar también las columnas usadas y parámetros básicos\n",
    "config_dict = {\n",
    "    \"text_column\": TEXT_COL,\n",
    "    \"target_column\": TARGET_COL,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"seed\": SEED\n",
    "}\n",
    "\n",
    "with open(final_model_dir / \"config_training.pkl\", \"wb\") as f:\n",
    "    pickle.dump(config_dict, f)\n",
    "\n",
    "print(\"Modelo y configuración guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d03be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "RESUMEN FINAL - MODELO BERT DETECCIÓN DE ODIO\n",
      "===============================================\n",
      "\n",
      "- Modelo base       : bert-base-uncased\n",
      "- Columna de texto  : Text\n",
      "- Columna objetivo  : IsHate\n",
      "- Tamaño Train (aug): 724\n",
      "- Tamaño Val        : 160\n",
      "\n",
      "Métricas finales:\n",
      "- Val F1            : 0.3119\n",
      "- Val Precision     : 0.4857\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_io.BufferedWriter' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Val F1            : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Val Precision     : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_prec\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m- Val Recall       : \u001b[39;49m\u001b[38;5;132;43;01m{val_rec:.4f}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Test F1           : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Test Precision    : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_prec\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: '_io.BufferedWriter' object is not callable"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 13. RESUMEN FINAL\n",
    "# =======================\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"RESUMEN FINAL - MODELO BERT DETECCIÓN DE ODIO\")\n",
    "print(\"===============================================\\n\")\n",
    "\n",
    "print(f\"- Modelo base       : {MODEL_NAME}\")\n",
    "print(f\"- Columna de texto  : {TEXT_COL}\")\n",
    "print(f\"- Columna objetivo  : {TARGET_COL}\")\n",
    "print(f\"- Tamaño Train (aug): {len(train_dataset)}\")\n",
    "print(f\"- Tamaño Val        : {len(val_dataset)}\")\n",
    "#print(f(\"- Tamaño Test      : {len(test_dataset)}\"))\n",
    "\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"- Val F1            : {val_f1:.4f}\")\n",
    "print(f\"- Val Precision     : {val_prec:.4f}\")\n",
    "print(f(\"- Val Recall       : {val_rec:.4f}\"))\n",
    "print(f\"- Test F1           : {test_f1:.4f}\")\n",
    "print(f\"- Test Precision    : {test_prec:.4f}\")\n",
    "print(f(\"- Test Recall       : {test_rec:.4f}\"))\n",
    "\n",
    "print(\"\\nControl de overfitting (aprox. diff F1 train-val final):\")\n",
    "print(f\"- F1 train final    : {train_f1_final:.4f}\")\n",
    "print(f(\"- F1 val final      : {val_f1:.4f}\"))\n",
    "print(f(\"- Diff F1           : {f1_diff_final:.4f} (objetivo < 0.05)\"))\n",
    "\n",
    "print(\"\\nArtefactos guardados:\")\n",
    "print(f\"- MLflow runs       : {MLRUNS_DIR}\")\n",
    "print(f(\"- Modelo HF         : {final_model_dir}\"))\n",
    "print(\"- Configuración     : config_training.pkl\")\n",
    "\n",
    "print(\"\\nPipeline completado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

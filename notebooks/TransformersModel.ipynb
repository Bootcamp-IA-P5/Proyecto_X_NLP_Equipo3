{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. IMPORTS Y CONFIGURACIÓN\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Para reproducibilidad\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", DEVICE)\n",
    "\n",
    "# Rutas (ajusta si tu estructura es distinta)\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "DATA_DIR = BASE_DIR / \"data/processed\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "MLRUNS_DIR = BASE_DIR / \"mlruns\"\n",
    "\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "MLRUNS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"BASE_DIR :\", BASE_DIR)\n",
    "print(\"DATA_DIR :\", DATA_DIR)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)\n",
    "print(\"MLRUNS_DIR:\", MLRUNS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc74a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. CARGA DEL DATASET PROCESADO (PICKLE)\n",
    "# ==========================================\n",
    "\n",
    "pkl_path = DATA_DIR / \"youtube_all_versions.pkl\"\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Si el pickle es un DataFrame directamente:\n",
    "if isinstance(data, pd.DataFrame):\n",
    "    df = data.copy()\n",
    "else:\n",
    "    # Si el pickle es un dict con varias versiones, elegimos una clave.\n",
    "    # AJUSTA 'text_clean' A LA CLAVE REAL QUE HAYAS USADO EN EL PREPROCESAMIENTO.\n",
    "    # Por ejemplo podría ser: 'Text_clean', 'text_processed', etc.\n",
    "    print(\"Claves disponibles en el pickle:\", list(data.keys()))\n",
    "    df = data[\"text_clean\"].copy()\n",
    "\n",
    "print(\"Dimensiones del DataFrame:\", df.shape)\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Comprobamos presencia de columnas clave\n",
    "assert \"Text\" in df.columns, \"No se encontró la columna 'Text' en el DataFrame.\"\n",
    "assert \"IsHate\" in df.columns, \"No se encontró la columna 'IsHate' en el DataFrame.\"\n",
    "\n",
    "# Vista rápida\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 3. SELECCIÓN DE COLUMNAS Y SPLIT TRAIN / VAL / TEST\n",
    "# =======================================================\n",
    "\n",
    "TEXT_COL = \"Text\"     # nombre exacto de la columna de texto\n",
    "TARGET_COL = \"IsHate\" # 0 = normal, 1 = odio\n",
    "\n",
    "# Subconjunto mínimo necesario\n",
    "df_model = df[[TEXT_COL, TARGET_COL]].dropna().copy()\n",
    "\n",
    "print(\"Distribución de clases (IsHate):\")\n",
    "print(df_model[TARGET_COL].value_counts(normalize=True).rename(\"ratio\"))\n",
    "\n",
    "X = df_model[TEXT_COL].values\n",
    "y = df_model[TARGET_COL].values.astype(int)\n",
    "\n",
    "# Train+Val vs Test (por ejemplo 80/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# Dentro de Train+Val, reservamos un 20% para validación (=> 64/16/20 global aprox.)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"  Train:\", len(X_train))\n",
    "print(\"  Val  :\", len(X_val))\n",
    "print(\"  Test :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3faee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 4. DATA AUGMENTATION LIGERO (OPCIONAL)\n",
    "# ===================================================\n",
    "# Aquí se hace un ejemplo muy simple: duplicar aleatoriamente algunos ejemplos\n",
    "# de la clase minoritaria con pequeñas perturbaciones (ej. shuffle de palabras).\n",
    "# Puedes sustituir esto por back-translation u otra técnica más sofisticada.\n",
    "\n",
    "def simple_word_shuffle(text, max_swaps=2):\n",
    "    words = text.split()\n",
    "    if len(words) < 4:\n",
    "        return text\n",
    "    n_swaps = random.randint(1, max_swaps)\n",
    "    words = words.copy()\n",
    "    for _ in range(n_swaps):\n",
    "        i, j = random.sample(range(len(words)), 2)\n",
    "        words[i], words[j] = words[j], words[i]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def augment_minority(X, y, factor=0.3):\n",
    "    X = list(X)\n",
    "    y = list(y)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Identificar clase minoritaria\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_counts = dict(zip(unique, counts))\n",
    "    print(\"Recuentos antes de augment:\", class_counts)\n",
    "\n",
    "    minority_class = min(class_counts, key=class_counts.get)\n",
    "    maj_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "    n_min = class_counts[minority_class]\n",
    "    n_maj = class_counts[maj_class]\n",
    "\n",
    "    # Número de nuevos ejemplos (por factor sobre minoria)\n",
    "    n_new = int(n_min * factor)\n",
    "    if n_new == 0:\n",
    "        return X, y\n",
    "\n",
    "    minority_indices = np.where(y == minority_class)[0]\n",
    "    new_texts = []\n",
    "    new_labels = []\n",
    "\n",
    "    for _ in range(n_new):\n",
    "        idx = random.choice(minority_indices)\n",
    "        original_text = X[idx]\n",
    "        aug_text = simple_word_shuffle(original_text)\n",
    "        new_texts.append(aug_text)\n",
    "        new_labels.append(minority_class)\n",
    "\n",
    "    X_aug = np.concatenate([X, np.array(new_texts)])\n",
    "    y_aug = np.concatenate([y, np.array(new_labels)])\n",
    "\n",
    "    unique2, counts2 = np.unique(y_aug, return_counts=True)\n",
    "    print(\"Recuentos después de augment:\", dict(zip(unique2, counts2)))\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "# Aplica augment solo al conjunto de entrenamiento\n",
    "X_train_aug, y_train_aug = augment_minority(X_train, y_train, factor=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbee636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 5. TOKENIZER Y DATASETS PARA TRANSFORMERS\n",
    "# ==============================================\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"  # puedes cambiarlo\n",
    "MAX_LENGTH = 128                  # ajusta si tus textos son más largos\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class HateDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = HateDataset(X_train_aug, y_train_aug, tokenizer, MAX_LENGTH)\n",
    "val_dataset   = HateDataset(X_val,      y_val,      tokenizer, MAX_LENGTH)\n",
    "test_dataset  = HateDataset(X_test,     y_test,     tokenizer, MAX_LENGTH)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# 6. CÁLCULO DE CLASS WEIGHTS (OPCIONAL)\n",
    "# =======================================\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array([0, 1]),\n",
    "    y=y_train_aug\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "print(\"Class weights:\", class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7. MODELO MULTILINGUAL BERT + OPTIMIZADOR + SCHEDULER\n",
    "# ==========================================\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "MULTILINGUAL_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "num_labels = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MULTILINGUAL_MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"bert.encoder.layer.\") and int(name.split(\".\")[3]) < 8:\n",
    "        param.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "EPOCHS = 4\n",
    "LR = 1e-5\n",
    "WARMUP_RATIO = 0.06\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LR,\n",
    "    weight_decay=0.05\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"Total steps:\", total_steps, \"Warmup steps:\", warmup_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88080f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 8. FUNCIONES TRAIN / EVAL LOOP\n",
    "# ===================================\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=None\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Grad clipping para estabilidad\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=None\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, f1, precision, recall, all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 9. CONFIGURACIÓN DE MLFLOW\n",
    "# ==============================\n",
    "\n",
    "# Directorio donde se guardan los mlruns al mismo nivel que notebooks\n",
    "mlflow.set_tracking_uri(f\"file:{MLRUNS_DIR}\")\n",
    "mlflow.set_experiment(\"bert_hate_detection_youtube\")\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 10. ENTRENAMIENTO CON MLFLOW + EARLY STOPPING\n",
    "#     (control overfitting <~5 puntos F1 train-val)\n",
    "# ======================================================\n",
    "\n",
    "PATIENCE = 2  # epochs sin mejora para parar\n",
    "BEST_VAL_F1 = 0.0\n",
    "PATIENCE_COUNTER = 0\n",
    "\n",
    "best_model_state = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"bert_base_youtube_hate\") as run:\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"max_length\", MAX_LENGTH)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"warmup_ratio\", WARMUP_RATIO)\n",
    "    mlflow.log_param(\"seed\", SEED)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"\\n===== Epoch {epoch}/{EPOCHS} =====\")\n",
    "\n",
    "        train_loss, train_f1, train_prec, train_rec = train_one_epoch(\n",
    "            model, train_loader, optimizer, scheduler, criterion, DEVICE\n",
    "        )\n",
    "        val_loss, val_f1, val_prec, val_rec, _, _ = eval_one_epoch(\n",
    "            model, val_loader, criterion, DEVICE\n",
    "        )\n",
    "\n",
    "        print(f\"Train  - Loss: {train_loss:.4f} | F1: {train_f1:.4f} | P: {train_prec:.4f} | R: {train_rec:.4f}\")\n",
    "        print(f\"Val    - Loss: {val_loss:.4f} | F1: {val_f1:.4f} | P: {val_prec:.4f} | R: {val_rec:.4f}\")\n",
    "\n",
    "        # Diferencia de F1 (aprox. overfitting)\n",
    "        f1_diff = train_f1 - val_f1\n",
    "        print(f\"Diff F1 (train - val): {f1_diff:.4f}\")\n",
    "\n",
    "        # Log en MLflow\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_f1\", train_f1, step=epoch)\n",
    "        mlflow.log_metric(\"train_precision\", train_prec, step=epoch)\n",
    "        mlflow.log_metric(\"train_recall\", train_rec, step=epoch)\n",
    "\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_f1\", val_f1, step=epoch)\n",
    "        mlflow.log_metric(\"val_precision\", val_prec, step=epoch)\n",
    "        mlflow.log_metric(\"val_recall\", val_rec, step=epoch)\n",
    "        mlflow.log_metric(\"f1_diff_train_val\", f1_diff, step=epoch)\n",
    "\n",
    "        # Early stopping por F1 de validación\n",
    "        if val_f1 > BEST_VAL_F1:\n",
    "            BEST_VAL_F1 = val_f1\n",
    "            PATIENCE_COUNTER = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(\">>> Nuevo mejor modelo (F1 val).\")\n",
    "        else:\n",
    "            PATIENCE_COUNTER += 1\n",
    "            print(f\"Sin mejora en F1 val. Patience {PATIENCE_COUNTER}/{PATIENCE}\")\n",
    "            if PATIENCE_COUNTER >= PATIENCE:\n",
    "                print(\">>> Early stopping activado.\")\n",
    "                break\n",
    "\n",
    "    # Restaurar mejores pesos\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Evaluación final en validación después de early stopping\n",
    "    val_loss, val_f1, val_prec, val_rec, _, _ = eval_one_epoch(\n",
    "        model, val_loader, criterion, DEVICE\n",
    "    )\n",
    "    print(\"\\nResultados finales en VALIDACIÓN:\")\n",
    "    print(f\"Loss: {val_loss:.4f} | F1: {val_f1:.4f} | P: {val_prec:.4f} | R: {val_rec:.4f}\")\n",
    "    mlflow.log_metric(\"final_val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"final_val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"final_val_precision\", val_prec)\n",
    "    mlflow.log_metric(\"final_val_recall\", val_rec)\n",
    "\n",
    "    # Puedes loguear también la diferencia de F1 final (medida de overfitting)\n",
    "    train_loss_final, train_f1_final, _, _ = train_one_epoch(\n",
    "        model, train_loader, optimizer, scheduler, criterion, DEVICE\n",
    "    )\n",
    "    f1_diff_final = train_f1_final - val_f1\n",
    "    print(f\"F1 train final: {train_f1_final:.4f} | Diff F1 final (train - val): {f1_diff_final:.4f}\")\n",
    "    mlflow.log_metric(\"final_train_f1\", train_f1_final)\n",
    "    mlflow.log_metric(\"final_f1_diff_train_val\", f1_diff_final)\n",
    "\n",
    "    # Log del modelo en MLflow\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 11. EVALUACIÓN EN CONJUNTO TEST\n",
    "# ===============================\n",
    "\n",
    "test_loss, test_f1, test_prec, test_rec, y_true_test, y_pred_test = eval_one_epoch(\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(\"Resultados en TEST:\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"F1  : {test_f1:.4f}\")\n",
    "print(f\"P   : {test_prec:.4f}\")\n",
    "print(f\"R   : {test_rec:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report (TEST):\")\n",
    "print(classification_report(y_true_test, y_pred_test, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 12. GUARDADO DEL MODELO Y TOKENIZER (../models)\n",
    "# =============================================\n",
    "\n",
    "final_model_dir = MODELS_DIR / \"bert_youtube_hate\"\n",
    "final_model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Guardando modelo en:\", final_model_dir)\n",
    "\n",
    "# Guardar modelo y tokenizer al estilo Hugging Face\n",
    "model.save_pretrained(final_model_dir)\n",
    "tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "# Guardar también las columnas usadas y parámetros básicos\n",
    "config_dict = {\n",
    "    \"text_column\": TEXT_COL,\n",
    "    \"target_column\": TARGET_COL,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"seed\": SEED\n",
    "}\n",
    "\n",
    "with open(final_model_dir / \"config_training.pkl\", \"wb\") as f:\n",
    "    pickle.dump(config_dict, f)\n",
    "\n",
    "print(\"Modelo y configuración guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d03be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 13. RESUMEN FINAL\n",
    "# =======================\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"RESUMEN FINAL - MODELO BERT DETECCIÓN DE ODIO\")\n",
    "print(\"===============================================\\n\")\n",
    "\n",
    "print(f\"- Modelo base       : {MODEL_NAME}\")\n",
    "print(f\"- Columna de texto  : {TEXT_COL}\")\n",
    "print(f\"- Columna objetivo  : {TARGET_COL}\")\n",
    "print(f\"- Tamaño Train (aug): {len(train_dataset)}\")\n",
    "print(f\"- Tamaño Val        : {len(val_dataset)}\")\n",
    "#print(f(\"- Tamaño Test      : {len(test_dataset)}\"))\n",
    "\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"- Val F1            : {val_f1:.4f}\")\n",
    "print(f\"- Val Precision     : {val_prec:.4f}\")\n",
    "print(f(\"- Val Recall       : {val_rec:.4f}\"))\n",
    "print(f\"- Test F1           : {test_f1:.4f}\")\n",
    "print(f\"- Test Precision    : {test_prec:.4f}\")\n",
    "print(f(\"- Test Recall       : {test_rec:.4f}\"))\n",
    "\n",
    "print(\"\\nControl de overfitting (aprox. diff F1 train-val final):\")\n",
    "print(f\"- F1 train final    : {train_f1_final:.4f}\")\n",
    "print(f(\"- F1 val final      : {val_f1:.4f}\"))\n",
    "print(f(\"- Diff F1           : {f1_diff_final:.4f} (objetivo < 0.05)\"))\n",
    "\n",
    "print(\"\\nArtefactos guardados:\")\n",
    "print(f\"- MLflow runs       : {MLRUNS_DIR}\")\n",
    "print(f(\"- Modelo HF         : {final_model_dir}\"))\n",
    "print(\"- Configuración     : config_training.pkl\")\n",
    "\n",
    "print(\"\\nPipeline completado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
